{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6068cb43-08a0-495c-b994-6ba409246db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import \\\n"
     ]
    }
   ],
   "source": [
    "from mmdeploy.apis import torch2onnx\n",
    "# from mmdeploy.backend.sdk.export_info import export2SDK\n",
    "import torch\n",
    "import onnx, onnxruntime\n",
    "from mmdeploy.apis.utils import build_task_processor\n",
    "from mmdeploy.utils import get_input_shape, load_config\n",
    "import torch\n",
    "import onnx\n",
    "import torch\n",
    "from onnx2torch import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50a351ba-24d1-41e6-aabc-1fbecc417fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 'demo/531__0_1200.png'\n",
    "work_dir = 'mmdeploy_models/mmdet/onnx'\n",
    "save_file = 'tinydet_l_aitod.onnx'\n",
    "deploy_cfg = '../mmdeploy/configs/mmdet/detection/detection_onnxruntime_custom.py'\n",
    "model_cfg = 'configs/tinydet/tinydet_L_aitod.py'\n",
    "model_checkpoint = 'work_dirs/tinydet_L_aitod/epoch_566.pth'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24bd947-2ad4-44b0-9d72-b05c3e7b753e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b2501c-1a2e-416e-9c97-e29e15e6c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_cfg, model_cfg = load_config(deploy_cfg, model_cfg)\n",
    "model_cfg['model']['test_cfg']['rcnn'] = None\n",
    "model_cfg['model']['test_cfg']['rpn']['nms_pre'] = -1\n",
    "deploy_cfg['input_shape'] = (512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4b2448-b611-4cec-abed-b704b1c948bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf42bb3-3fa0-4381-b637-0071ebc062f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/27 11:30:49 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet\" in the \"Codebases\" registry tree. As a workaround, the current \"Codebases\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet\" is a correct scope, or whether the registry is initialized.\n",
      "01/27 11:30:49 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet\" in the \"mmdet_tasks\" registry tree. As a workaround, the current \"mmdet_tasks\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet\" is a correct scope, or whether the registry is initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmengine/runner/checkpoint.py:347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, map_location=map_location)\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: conv2.0.weight, conv2.1.weight, conv2.1.bias, conv2.1.running_mean, conv2.1.running_var, conv2.1.num_batches_tracked, linear3.0.weight, linear3.0.bias, linear4.weight, linear4.bias\n",
      "\n",
      "missing keys in source state_dict: blocks.18.se.se.1.weight, blocks.18.se.se.3.weight, blocks.18.conv1.weight, blocks.18.bn1.weight, blocks.18.bn1.bias, blocks.18.bn1.running_mean, blocks.18.bn1.running_var, blocks.18.conv2.weight, blocks.18.bn2.weight, blocks.18.bn2.bias, blocks.18.bn2.running_mean, blocks.18.bn2.running_var, blocks.18.conv3.weight, blocks.18.bn3.weight, blocks.18.bn3.bias, blocks.18.bn3.running_mean, blocks.18.bn3.running_var, blocks.19.se.se.1.weight, blocks.19.se.se.3.weight, blocks.19.conv1.weight, blocks.19.bn1.weight, blocks.19.bn1.bias, blocks.19.bn1.running_mean, blocks.19.bn1.running_var, blocks.19.conv2.weight, blocks.19.bn2.weight, blocks.19.bn2.bias, blocks.19.bn2.running_mean, blocks.19.bn2.running_var, blocks.19.conv3.weight, blocks.19.bn3.weight, blocks.19.bn3.bias, blocks.19.bn3.running_mean, blocks.19.bn3.running_var\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "{'type': 'PSROIAlign_ori', 'roi_size': 7, 'sampling_ratio': 2, 'pooled_dim': 5}\n",
      "PSROIAlign_ori\n",
      "--------------------------\n",
      "{'type': 'PSROIAlign_ori', 'roi_size': 7, 'sampling_ratio': 2, 'pooled_dim': 5}\n",
      "PSROIAlign_ori\n",
      "Loads checkpoint by local backend from path: work_dirs/tinydet_L_aitod/epoch_566.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meysam/test-apps/mmdetection/mmdet/models/task_modules/builder.py:24: UserWarning: ``build_iou_calculator`` would be deprecated soon, please use ``mmdet.registry.TASK_UTILS.build()`` \n",
      "  warnings.warn(\n",
      "/home/meysam/test-apps/mmdetection/mmdet/models/dense_heads/anchor_head.py:108: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n"
     ]
    }
   ],
   "source": [
    "# deploy_cfg, model_cfg = load_config(deploy_cfg, model_cfg)\n",
    "task_processor = build_task_processor(model_cfg, deploy_cfg, device)\n",
    "torch_model = task_processor.build_pytorch_model(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a21665f5-9d87-40d8-9145-f83d79498458",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_inp = torch.randn(1,3,512,512).cuda()\n",
    "input_shape = get_input_shape(deploy_cfg)\n",
    "model_inputs, _ = task_processor.create_input(img, input_shape)\n",
    "batch_data_samples = model_inputs.get('data_samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc9a0694-a25f-4a3d-bdad-95c03001d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1,3,512,512).cuda()\n",
    "feat = torch_model.extract_feat(x) # backbone and necks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7cd7154-1b81-4988-aabd-400568f254df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 245, 128, 128])\n",
      "torch.Size([1, 245, 64, 64])\n",
      "torch.Size([1, 245, 32, 32])\n",
      "torch.Size([1, 245, 16, 16])\n",
      "torch.Size([1, 245, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "for ff in feat:\n",
    "    print(f\"{ff.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "535de247-84c6-4d1d-9af8-bd55198f7837",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn_results_list = torch_model.rpn_head.predict(\n",
    "        feat, batch_data_samples, rescale=False)\n",
    "roi_outs = torch_model.roi_head.forward(feat, rpn_results_list,\n",
    "                                         batch_data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e2b2ecf1-367a-401e-aac8-9dca032e39f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 4])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpn_results_list[0].bboxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c6df46a-696f-475b-8569-a2cd5449f671",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = torch_model.rpn_head(feat)\n",
    "# BaseDenseHead . predict_by_feat(*outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc421a37-1eab-4ba4-80a1-fa3507f736a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_scores = outs[0]\n",
    "bbox_preds = outs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "782a750d-98c5-4737-a715-31250ddb3c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 3, 64, 64])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 16, 16])\n",
      "torch.Size([1, 3, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "for cc in cls_scores:\n",
    "    print(cc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fd8a4e3e-d37d-4d4f-8a58-79725d4d3a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 128, 128])\n",
      "torch.Size([1, 12, 64, 64])\n",
      "torch.Size([1, 12, 32, 32])\n",
      "torch.Size([1, 12, 16, 16])\n",
      "torch.Size([1, 12, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "for bb in bbox_preds:\n",
    "    print(bb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8b951ca8-31af-4fc4-b3aa-87b4f965408f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 10])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_outs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "20d8f02f-c69a-49d7-80da-3e1c46480426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 4])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_outs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb06a271-bbc0-40c0-a6e7-60d1593672e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'bboxes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m roi_outs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroi_head\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrpn_results_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_data_samples\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/test-apps/mmdetection/mmdet/models/roi_heads/standard_roi_head.py:80\u001b[0m, in \u001b[0;36mStandardRoIHead.forward\u001b[0;34m(self, x, rpn_results_list, batch_data_samples)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Network forward process. Usually includes backbone, neck and head\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03mforward without any post-processing.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    forward.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m results \u001b[38;5;241m=\u001b[39m ()\n\u001b[0;32m---> 80\u001b[0m proposals \u001b[38;5;241m=\u001b[39m [\u001b[43mrpn_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbboxes\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m rpn_results \u001b[38;5;129;01min\u001b[39;00m rpn_results_list]\n\u001b[1;32m     81\u001b[0m rois \u001b[38;5;241m=\u001b[39m bbox2roi(proposals)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# bbox head\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'bboxes'"
     ]
    }
   ],
   "source": [
    "roi_outs = torch_model.roi_head.forward(x, rpn_results_list, batch_data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4b667a2-dca1-4778-943b-1d4e06b09828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleRoIExtractorModified(\n",
       "  (roi_layers): ModuleList(\n",
       "    (0): PSRoIAlign(output_size=7, spatial_scale=0.25, sampling_ratio=2)\n",
       "    (1): PSRoIAlign(output_size=7, spatial_scale=0.125, sampling_ratio=2)\n",
       "    (2): PSRoIAlign(output_size=7, spatial_scale=0.0625, sampling_ratio=2)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model.roi_head.bbox_roi_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f46a060-206f-472e-8d99-d0d73f4ce413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rpn_results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02769fea-b52a-462f-aeee-41c7a5fe2a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rpn_results_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e5c2dbb-6bba-43c1-986e-0d945507414d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rpn_results_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83c3491a-cdf3-43d1-95f4-1dfa6b2a878b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128, 128])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpn_results_list[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7de69e9a-e19c-46df-b885-50e50201d513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 64, 64])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpn_results_list[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b04eec46-91a5-4f91-8932-ee8c69df07fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpn_results_list[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a747f8a-36ac-4a0c-8f85-a45768b21757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 16, 16])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpn_results_list[0][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8e8bdda-d8d1-478b-b487-0425ada6d4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 8, 8])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpn_results_list[0][4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8d7cf-b45d-4f83-94ea-d2898cc89be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47591d98-98e2-40ee-b35a-8804079bb3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa11df38-d17e-494c-8b1b-d71b8a5a7ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ea4597-38e0-40f0-9f47-9a2d669fcccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4780a677-2e53-420a-90b6-dc0756ef198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "        rpn_results_list = self.torch_model.rpn_head.predict(\n",
    "                x, batch_data_samples, rescale=False)\n",
    "        labels = rpn_results_list[0].get('labels')\n",
    "        bboxes = rpn_results_list[0].get('bboxes')\n",
    "        scores = rpn_results_list[0].get('scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2069ce8c-028a-42c0-ad52-a4ac14982f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72b5bb86-61c8-44bb-a827-751f9aef335a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m oo \u001b[38;5;241m=\u001b[39m torch_model\u001b[38;5;241m.\u001b[39m_forward(\u001b[43mx\u001b[49m, batch_data_samples)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "oo = torch_model._forward(x, batch_data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83b84f84-5647-4ad9-9723-113106d1fb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyRPN(\n",
       "  (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n",
       "  (loss_bbox): SmoothL1Loss()\n",
       "  (rpn_conv): Sequential(\n",
       "    (0): Conv2d(245, 245, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=245)\n",
       "    (1): Conv2d(245, 245, kernel_size=(1, 1), stride=(1, 1), groups=49)\n",
       "  )\n",
       "  (rpn_cls): Conv2d(245, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (rpn_reg): Conv2d(245, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       ")\n",
       "init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model.rpn_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22655cd2-729b-4c47-860b-8246cb8ed176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardRoIHead(\n",
       "  (bbox_roi_extractor): SingleRoIExtractorModified(\n",
       "    (roi_layers): ModuleList(\n",
       "      (0): PSRoIAlign(output_size=7, spatial_scale=0.25, sampling_ratio=2)\n",
       "      (1): PSRoIAlign(output_size=7, spatial_scale=0.125, sampling_ratio=2)\n",
       "      (2): PSRoIAlign(output_size=7, spatial_scale=0.0625, sampling_ratio=2)\n",
       "    )\n",
       "  )\n",
       "  (bbox_head): SharedFCBBoxHeadModified(\n",
       "    (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n",
       "    (loss_bbox): SmoothL1Loss()\n",
       "    (fc_cls): Linear(in_features=1024, out_features=10, bias=True)\n",
       "    (fc_reg): Linear(in_features=1024, out_features=4, bias=True)\n",
       "    (shared_convs): ModuleList()\n",
       "    (shared_fcs): ModuleList(\n",
       "      (0): Linear(in_features=245, out_features=1024, bias=True)\n",
       "    )\n",
       "    (cls_convs): ModuleList()\n",
       "    (cls_fcs): ModuleList()\n",
       "    (reg_convs): ModuleList()\n",
       "    (reg_fcs): ModuleList()\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model.roi_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddd2fc1c-6d2a-4c7e-9333-63793f51111d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'oo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moo\u001b[49m[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'oo' is not defined"
     ]
    }
   ],
   "source": [
    "oo[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d91cd8f-bffa-4c7a-98d6-bb8404e4c083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca2f86-6115-4b0a-94f1-877a09994788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2155e989-8023-4a36-9482-825911dbe6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3364e+02, 1.6008e-01, 1.5197e+02, 1.1681e+01],\n",
       "        [0.0000e+00, 7.3067e+02, 2.6543e+02, 8.0000e+02],\n",
       "        [2.8536e+00, 7.1339e+02, 1.7606e+02, 8.0000e+02],\n",
       "        ...,\n",
       "        [1.5132e+02, 2.4669e+01, 1.6611e+02, 4.0586e+01],\n",
       "        [4.6649e+02, 2.9237e+01, 4.7864e+02, 4.8260e+01],\n",
       "        [3.5899e+02, 1.2757e+01, 3.8208e+02, 2.8822e+01]], device='cuda:0',\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].get('pred_instances').get('bboxes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc753de0-71b5-4459-8930-cba95e970ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2d4d1c-cdb7-4997-9619-f3d3257c9add",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5436a37-bcdf-4563-bed3-f3121525d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelForExport(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelForExport, self).__init__()\n",
    "        self.torch_model = task_processor.build_pytorch_model(model_checkpoint)\n",
    "        # torch_model.eval()\n",
    "    def forward(self, x):\n",
    "        results = ()\n",
    "        x = self.torch_model.extract_feat(x)\n",
    "        rpn_results_list = self.torch_model.rpn_head.predict(\n",
    "                x, batch_data_samples, rescale=False)\n",
    "        # labels = rpn_results_list[0].get('labels')\n",
    "        # bboxes = rpn_results_list[0].get('bboxes')\n",
    "        # scores = rpn_results_list[0].get('scores')\n",
    "\n",
    "        # print(len(rpn_results_list))\n",
    "        # print(rpn_results_list[0].keys())\n",
    "        # ['labels', 'bboxes', 'scores']\n",
    "        # labels = \n",
    "        \n",
    "        roi_outs = self.torch_model.roi_head.forward(x, rpn_results_list,\n",
    "                                         batch_data_samples)\n",
    "        return roi_outs[0], roi_outs[1]\n",
    "        # return labels, bboxes, scores\n",
    "    # def forward(self, x):\n",
    "        # out = self.torch_model.forward(x, batch_data_samples)\n",
    "        # return out[0][0], out[0][1]\n",
    "        # out = torch_model.predict2(t_inp, batch_data_samples)\n",
    "        # return out[0].get('pred_instances').get('bboxes'), out[0].get('pred_instances').get('scores')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4aa5ddf3-77be-44e0-bf75-4c5bfdbd804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: conv2.0.weight, conv2.1.weight, conv2.1.bias, conv2.1.running_mean, conv2.1.running_var, conv2.1.num_batches_tracked, linear3.0.weight, linear3.0.bias, linear4.weight, linear4.bias\n",
      "\n",
      "missing keys in source state_dict: blocks.18.se.se.1.weight, blocks.18.se.se.3.weight, blocks.18.conv1.weight, blocks.18.bn1.weight, blocks.18.bn1.bias, blocks.18.bn1.running_mean, blocks.18.bn1.running_var, blocks.18.conv2.weight, blocks.18.bn2.weight, blocks.18.bn2.bias, blocks.18.bn2.running_mean, blocks.18.bn2.running_var, blocks.18.conv3.weight, blocks.18.bn3.weight, blocks.18.bn3.bias, blocks.18.bn3.running_mean, blocks.18.bn3.running_var, blocks.19.se.se.1.weight, blocks.19.se.se.3.weight, blocks.19.conv1.weight, blocks.19.bn1.weight, blocks.19.bn1.bias, blocks.19.bn1.running_mean, blocks.19.bn1.running_var, blocks.19.conv2.weight, blocks.19.bn2.weight, blocks.19.bn2.bias, blocks.19.bn2.running_mean, blocks.19.bn2.running_var, blocks.19.conv3.weight, blocks.19.bn3.weight, blocks.19.bn3.bias, blocks.19.bn3.running_mean, blocks.19.bn3.running_var\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "{'type': 'PSROIAlign_ori', 'roi_size': 7, 'sampling_ratio': 2, 'pooled_dim': 5}\n",
      "PSROIAlign_ori\n",
      "--------------------------\n",
      "{'type': 'PSROIAlign_ori', 'roi_size': 7, 'sampling_ratio': 2, 'pooled_dim': 5}\n",
      "PSROIAlign_ori\n",
      "Loads checkpoint by local backend from path: work_dirs/tinydet_L_aitod/epoch_566.pth\n"
     ]
    }
   ],
   "source": [
    "model_to_export = ModelForExport()\n",
    "model_to_export.eval()\n",
    "model_to_export.cuda()\n",
    "x = torch.randn(1,3,512,512).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3359ca74-5abe-4e1c-a7d5-d3df079dc7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels, bboxes, scores = model_to_export(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80e34049-ca0b-4879-8a23-89ce3f527d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_outs = model_to_export(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0d4c342-a984-4956-9bc8-39fc022915e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 10])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_outs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7bfd38fb-43d1-4763-8860-036a1bfb921c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 4])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_outs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073dc2bc-f615-4049-8d56-238868a90326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f8fd25c7-241d-4f1b-ab8d-d05ed5870328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardRoIHead(\n",
       "  (bbox_roi_extractor): SingleRoIExtractorModified(\n",
       "    (roi_layers): ModuleList(\n",
       "      (0): PSRoIAlign(output_size=7, spatial_scale=0.25, sampling_ratio=2)\n",
       "      (1): PSRoIAlign(output_size=7, spatial_scale=0.125, sampling_ratio=2)\n",
       "      (2): PSRoIAlign(output_size=7, spatial_scale=0.0625, sampling_ratio=2)\n",
       "    )\n",
       "  )\n",
       "  (bbox_head): SharedFCBBoxHeadModified(\n",
       "    (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n",
       "    (loss_bbox): SmoothL1Loss()\n",
       "    (fc_cls): Linear(in_features=1024, out_features=10, bias=True)\n",
       "    (fc_reg): Linear(in_features=1024, out_features=4, bias=True)\n",
       "    (shared_convs): ModuleList()\n",
       "    (shared_fcs): ModuleList(\n",
       "      (0): Linear(in_features=245, out_features=1024, bias=True)\n",
       "    )\n",
       "    (cls_convs): ModuleList()\n",
       "    (cls_fcs): ModuleList()\n",
       "    (reg_convs): ModuleList()\n",
       "    (reg_fcs): ModuleList()\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model.roi_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c6baaf5-54a4-419e-93b0-818f06614b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meysam/test-apps/mmdetection/mmdet/models/dense_heads/base_dense_head.py:393: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert cls_score.size()[-2:] == bbox_pred.size()[-2:]\n",
      "/home/meysam/test-apps/mmdetection/mmdet/models/utils/misc.py:336: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  num_topk = min(topk, valid_idxs.size(0))\n",
      "/home/meysam/test-apps/mmdetection/mmdet/models/task_modules/coders/delta_xywh_bbox_coder.py:100: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert pred_bboxes.size(0) == bboxes.size(0)\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmengine/structures/instance_data.py:309: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  return len(self.values()[0])\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmengine/structures/instance_data.py:155: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  assert len(value) == len(self), 'The length of ' \\\n",
      "/home/meysam/test-apps/mmdetection/mmdet/models/dense_heads/base_dense_head.py:509: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not valid_mask.all():\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmengine/structures/instance_data.py:201: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  assert len(item) == len(self), 'The shape of the ' \\\n",
      "/home/meysam/test-apps/mmdetection/mmdet/models/dense_heads/base_dense_head.py:513: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if with_nms and results.bboxes.numel() > 0:\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmcv/ops/nms.py:276: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if boxes.size(-1) == 5:\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmcv/ops/nms.py:293: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  max_coordinate + torch.tensor(1).to(boxes))\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmcv/ops/nms.py:302: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if boxes_for_nms.shape[0] < split_thr:\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmcv/ops/nms.py:317: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  for id in torch.unique(idxs):\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmcv/ops/nms.py:123: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert boxes.size(1) == 4\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmcv/ops/nms.py:124: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert boxes.size(0) == scores.size(0)\n",
      "/home/meysam/test-apps/mmdetection/mmdet/models/roi_heads/roi_extractors/single_level_modified.py:171: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if inds.any():\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/torch/__init__.py:2040: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n"
     ]
    },
    {
     "ename": "UnsupportedOperatorError",
     "evalue": "ONNX export failed on an operator with unrecognized namespace torchvision::ps_roi_align. If you are trying to export a custom operator, make sure you registered it with the right domain and version.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedOperatorError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# if not os.path.isfile(ONNX_FILE_PATH):\u001b[39;00m\n\u001b[1;32m      2\u001b[0m ONNX_FILE_PATH \u001b[38;5;241m=\u001b[39m work_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m save_file\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_export\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mONNX_FILE_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbboxes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclasses\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/onnx/__init__.py:375\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, kwargs, export_params, verbose, input_names, output_names, opset_version, dynamic_axes, keep_initializers_as_inputs, dynamo, external_data, dynamic_shapes, report, verify, profile, dump_exported_program, artifacts_dir, fallback, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining, **_)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dynamic_shapes:\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe exporter only supports dynamic shapes \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthrough parameter dynamic_axes when dynamo=False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    373\u001b[0m     )\n\u001b[0;32m--> 375\u001b[0m \u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/onnx/utils.py:502\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, kwargs, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;241m+\u001b[39m (kwargs,)\n\u001b[0;32m--> 502\u001b[0m \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/onnx/utils.py:1564\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1562\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1564\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1578\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1579\u001b[0m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _exporter_states\u001b[38;5;241m.\u001b[39mExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1580\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/onnx/utils.py:1117\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1114\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1117\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43m_optimize_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_disable_torch_constant_prop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_disable_torch_constant_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1128\u001b[0m     torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch IR graph at exception: \u001b[39m\u001b[38;5;124m\"\u001b[39m, graph)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/onnx/utils.py:639\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[1;32m    636\u001b[0m     _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_set_dynamic_input_shape(graph, dynamic_axes, input_names)\n\u001b[1;32m    637\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[0;32m--> 639\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jit_pass_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m    641\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_lint(graph)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/onnx/utils.py:1848\u001b[0m, in \u001b[0;36m_run_symbolic_function\u001b[0;34m(graph, block, node, inputs, env, values_in_env, new_nodes, operator_export_type)\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m namespace \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1843\u001b[0m         \u001b[38;5;66;03m# Clone node to trigger ONNX shape inference\u001b[39;00m\n\u001b[1;32m   1844\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m graph_context\u001b[38;5;241m.\u001b[39mop(\n\u001b[1;32m   1845\u001b[0m             op_name, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mattrs, outputs\u001b[38;5;241m=\u001b[39mnode\u001b[38;5;241m.\u001b[39moutputsSize()\n\u001b[1;32m   1846\u001b[0m         )  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m-> 1848\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mUnsupportedOperatorError(\n\u001b[1;32m   1849\u001b[0m         symbolic_function_name,\n\u001b[1;32m   1850\u001b[0m         opset_version,\n\u001b[1;32m   1851\u001b[0m         symbolic_function_group\u001b[38;5;241m.\u001b[39mget_min_supported()\n\u001b[1;32m   1852\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m symbolic_function_group\n\u001b[1;32m   1853\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1854\u001b[0m     )\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[1;32m   1857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m operator_export_type \u001b[38;5;241m==\u001b[39m _C_onnx\u001b[38;5;241m.\u001b[39mOperatorExportTypes\u001b[38;5;241m.\u001b[39mONNX_FALLTHROUGH:\n",
      "\u001b[0;31mUnsupportedOperatorError\u001b[0m: ONNX export failed on an operator with unrecognized namespace torchvision::ps_roi_align. If you are trying to export a custom operator, make sure you registered it with the right domain and version."
     ]
    }
   ],
   "source": [
    "# if not os.path.isfile(ONNX_FILE_PATH):\n",
    "ONNX_FILE_PATH = work_dir + '/'+ save_file\n",
    "torch.onnx.export(model_to_export, (x), ONNX_FILE_PATH, input_names=[\"x\"], \n",
    "                output_names=[\"bboxes\",\"classes\"], export_params=True) #external_data=True , opset_version = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a3498-f53a-48bd-ac95-86fcb86409d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b152d150-ae3b-4437-b4da-07bd2ed3288e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5794eedd-205c-4615-b6ea-4a33a832c0df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8ccaa01-aa89-4dc1-9341-7144625eb069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meysam/test-apps/mmdetection/mmdet/models/dense_heads/base_dense_head.py:393: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert cls_score.size()[-2:] == bbox_pred.size()[-2:]\n",
      "/home/meysam/test-apps/mmdetection/mmdet/models/utils/misc.py:336: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  num_topk = min(topk, valid_idxs.size(0))\n",
      "/home/meysam/test-apps/mmdetection/mmdet/models/task_modules/coders/delta_xywh_bbox_coder.py:100: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert pred_bboxes.size(0) == bboxes.size(0)\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmengine/structures/instance_data.py:309: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  return len(self.values()[0])\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmengine/structures/instance_data.py:155: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  assert len(value) == len(self), 'The length of ' \\\n",
      "/home/meysam/test-apps/mmdetection/mmdet/models/dense_heads/base_dense_head.py:509: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not valid_mask.all():\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmengine/structures/instance_data.py:201: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  assert len(item) == len(self), 'The shape of the ' \\\n",
      "/home/meysam/test-apps/mmdetection/mmdet/models/dense_heads/base_dense_head.py:513: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if with_nms and results.bboxes.numel() > 0:\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmcv/ops/nms.py:276: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if boxes.size(-1) == 5:\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmcv/ops/nms.py:293: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  max_coordinate + torch.tensor(1).to(boxes))\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmcv/ops/nms.py:302: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if boxes_for_nms.shape[0] < split_thr:\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmcv/ops/nms.py:317: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  for id in torch.unique(idxs):\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmcv/ops/nms.py:123: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert boxes.size(1) == 4\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmcv/ops/nms.py:124: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert boxes.size(0) == scores.size(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# if not os.path.isfile(ONNX_FILE_PATH):\n",
    "ONNX_FILE_PATH = work_dir + '/'+ save_file\n",
    "torch.onnx.export(model_to_export, (x), ONNX_FILE_PATH, input_names=[\"x\"], \n",
    "                output_names=[\"bboxes\",\"scores\",\"scores\"], export_params=True) #external_data=True , opset_version = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c306a693-7135-49ff-9b46-6e85d817ce97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function export in module torch.onnx:\n",
      "\n",
      "export(model: 'torch.nn.Module | torch.export.ExportedProgram | torch.jit.ScriptModule | torch.jit.ScriptFunction', args: 'tuple[Any, ...]' = (), f: 'str | os.PathLike | None' = None, *, kwargs: 'dict[str, Any] | None' = None, export_params: 'bool' = True, verbose: 'bool | None' = None, input_names: 'Sequence[str] | None' = None, output_names: 'Sequence[str] | None' = None, opset_version: 'int | None' = None, dynamic_axes: 'Mapping[str, Mapping[int, str]] | Mapping[str, Sequence[int]] | None' = None, keep_initializers_as_inputs: 'bool' = False, dynamo: 'bool' = False, external_data: 'bool' = True, dynamic_shapes: 'dict[str, Any] | tuple[Any, ...] | list[Any] | None' = None, report: 'bool' = False, verify: 'bool' = False, profile: 'bool' = False, dump_exported_program: 'bool' = False, artifacts_dir: 'str | os.PathLike' = '.', fallback: 'bool' = False, training: '_C_onnx.TrainingMode' = <TrainingMode.EVAL: 0>, operator_export_type: '_C_onnx.OperatorExportTypes' = <OperatorExportTypes.ONNX: 0>, do_constant_folding: 'bool' = True, custom_opsets: 'Mapping[str, int] | None' = None, export_modules_as_functions: 'bool | Collection[type[torch.nn.Module]]' = False, autograd_inlining: 'bool' = True, **_: 'Any') -> 'Any | None'\n",
      "    Exports a model into ONNX format.\n",
      "\n",
      "    Args:\n",
      "        model: The model to be exported.\n",
      "        args: Example positional inputs. Any non-Tensor arguments will be hard-coded into the\n",
      "            exported model; any Tensor arguments will become inputs of the exported model,\n",
      "            in the order they occur in the tuple.\n",
      "        f: Path to the output ONNX model file. E.g. \"model.onnx\".\n",
      "        kwargs: Optional example keyword inputs.\n",
      "        export_params: If false, parameters (weights) will not be exported.\n",
      "        verbose: Whether to enable verbose logging.\n",
      "        input_names: names to assign to the input nodes of the graph, in order.\n",
      "        output_names: names to assign to the output nodes of the graph, in order.\n",
      "        opset_version: The version of the\n",
      "            `default (ai.onnx) opset <https://github.com/onnx/onnx/blob/master/docs/Operators.md>`_\n",
      "            to target. Must be >= 7.\n",
      "        dynamic_axes:\n",
      "\n",
      "            By default the exported model will have the shapes of all input and output tensors\n",
      "            set to exactly match those given in ``args``. To specify axes of tensors as\n",
      "            dynamic (i.e. known only at run-time), set ``dynamic_axes`` to a dict with schema:\n",
      "\n",
      "            * KEY (str): an input or output name. Each name must also be provided in ``input_names`` or\n",
      "                ``output_names``.\n",
      "            * VALUE (dict or list): If a dict, keys are axis indices and values are axis names. If a\n",
      "                list, each element is an axis index.\n",
      "\n",
      "            For example::\n",
      "\n",
      "                class SumModule(torch.nn.Module):\n",
      "                    def forward(self, x):\n",
      "                        return torch.sum(x, dim=1)\n",
      "\n",
      "\n",
      "                torch.onnx.export(\n",
      "                    SumModule(),\n",
      "                    (torch.ones(2, 2),),\n",
      "                    \"onnx.pb\",\n",
      "                    input_names=[\"x\"],\n",
      "                    output_names=[\"sum\"],\n",
      "                )\n",
      "\n",
      "            Produces::\n",
      "\n",
      "                input {\n",
      "                  name: \"x\"\n",
      "                  ...\n",
      "                      shape {\n",
      "                        dim {\n",
      "                          dim_value: 2  # axis 0\n",
      "                        }\n",
      "                        dim {\n",
      "                          dim_value: 2  # axis 1\n",
      "                ...\n",
      "                output {\n",
      "                  name: \"sum\"\n",
      "                  ...\n",
      "                      shape {\n",
      "                        dim {\n",
      "                          dim_value: 2  # axis 0\n",
      "                ...\n",
      "\n",
      "            While::\n",
      "\n",
      "                torch.onnx.export(\n",
      "                    SumModule(),\n",
      "                    (torch.ones(2, 2),),\n",
      "                    \"onnx.pb\",\n",
      "                    input_names=[\"x\"],\n",
      "                    output_names=[\"sum\"],\n",
      "                    dynamic_axes={\n",
      "                        # dict value: manually named axes\n",
      "                        \"x\": {0: \"my_custom_axis_name\"},\n",
      "                        # list value: automatic names\n",
      "                        \"sum\": [0],\n",
      "                    },\n",
      "                )\n",
      "\n",
      "            Produces::\n",
      "\n",
      "                input {\n",
      "                  name: \"x\"\n",
      "                  ...\n",
      "                      shape {\n",
      "                        dim {\n",
      "                          dim_param: \"my_custom_axis_name\"  # axis 0\n",
      "                        }\n",
      "                        dim {\n",
      "                          dim_value: 2  # axis 1\n",
      "                ...\n",
      "                output {\n",
      "                  name: \"sum\"\n",
      "                  ...\n",
      "                      shape {\n",
      "                        dim {\n",
      "                          dim_param: \"sum_dynamic_axes_1\"  # axis 0\n",
      "                ...\n",
      "\n",
      "        keep_initializers_as_inputs: If True, all the\n",
      "            initializers (typically corresponding to model weights) in the\n",
      "            exported graph will also be added as inputs to the graph. If False,\n",
      "            then initializers are not added as inputs to the graph, and only\n",
      "            the user inputs are added as inputs.\n",
      "\n",
      "            Set this to True if you intend to supply model weights at runtime.\n",
      "            Set it to False if the weights are static to allow for better optimizations\n",
      "            (e.g. constant folding) by backends/runtimes.\n",
      "\n",
      "        dynamo: Whether to export the model with ``torch.export`` ExportedProgram instead of TorchScript.\n",
      "        external_data: Whether to save the model weights as an external data file.\n",
      "            This is required for models with large weights that exceed the ONNX file size limit (2GB).\n",
      "            When False, the weights are saved in the ONNX file with the model architecture.\n",
      "        dynamic_shapes: A dictionary of dynamic shapes for the model inputs. Refer to\n",
      "            :func:`torch.export.export` for more details. This is only used (and preferred) when dynamo is True.\n",
      "            Only one parameter `dynamic_axes` or `dynamic_shapes` should be set\n",
      "            at the same time.\n",
      "        report: Whether to generate a markdown report for the export process.\n",
      "        verify: Whether to verify the exported model using ONNX Runtime.\n",
      "        profile: Whether to profile the export process.\n",
      "        dump_exported_program: Whether to dump the :class:`torch.export.ExportedProgram` to a file.\n",
      "            This is useful for debugging the exporter.\n",
      "        artifacts_dir: The directory to save the debugging artifacts like the report and the serialized\n",
      "            exported program.\n",
      "        fallback: Whether to fallback to the TorchScript exporter if the dynamo exporter fails.\n",
      "\n",
      "        training: Deprecated option. Instead, set the training mode of the model before exporting.\n",
      "        operator_export_type: Deprecated option. Only ONNX is supported.\n",
      "        do_constant_folding: Deprecated option. The exported graph is always optimized.\n",
      "        custom_opsets: Deprecated.\n",
      "            A dictionary:\n",
      "\n",
      "            * KEY (str): opset domain name\n",
      "            * VALUE (int): opset version\n",
      "\n",
      "            If a custom opset is referenced by ``model`` but not mentioned in this dictionary,\n",
      "            the opset version is set to 1. Only custom opset domain name and version should be\n",
      "            indicated through this argument.\n",
      "        export_modules_as_functions: Deprecated option.\n",
      "\n",
      "            Flag to enable\n",
      "            exporting all ``nn.Module`` forward calls as local functions in ONNX. Or a set to indicate the\n",
      "            particular types of modules to export as local functions in ONNX.\n",
      "            This feature requires ``opset_version`` >= 15, otherwise the export will fail. This is because\n",
      "            ``opset_version`` < 15 implies IR version < 8, which means no local function support.\n",
      "            Module variables will be exported as function attributes. There are two categories of function\n",
      "            attributes.\n",
      "\n",
      "            1. Annotated attributes: class variables that have type annotations via\n",
      "            `PEP 526-style <https://www.python.org/dev/peps/pep-0526/#class-and-instance-variable-annotations>`_\n",
      "            will be exported as attributes.\n",
      "            Annotated attributes are not used inside the subgraph of ONNX local function because\n",
      "            they are not created by PyTorch JIT tracing, but they may be used by consumers\n",
      "            to determine whether or not to replace the function with a particular fused kernel.\n",
      "\n",
      "            2. Inferred attributes: variables that are used by operators inside the module. Attribute names\n",
      "            will have prefix \"inferred::\". This is to differentiate from predefined attributes retrieved from\n",
      "            python module annotations. Inferred attributes are used inside the subgraph of ONNX local function.\n",
      "\n",
      "            * ``False`` (default): export ``nn.Module`` forward calls as fine grained nodes.\n",
      "            * ``True``: export all ``nn.Module`` forward calls as local function nodes.\n",
      "            * Set of type of nn.Module: export ``nn.Module`` forward calls as local function nodes,\n",
      "                only if the type of the ``nn.Module`` is found in the set.\n",
      "        autograd_inlining: Deprecated.\n",
      "            Flag used to control whether to inline autograd functions.\n",
      "            Refer to https://github.com/pytorch/pytorch/pull/74765 for more details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.onnx.export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1653646d-cca1-4057-a81b-95d3d7c4b89d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e900656-8175-4cd6-834d-ee80690eb4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b06b20f6-ee25-42f6-b20f-50f30223e35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 9])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "857d426d-c392-4db9-b4f6-9f5dbcf7e3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 32])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b64d5e0f-7529-48cd-87b1-129bcc7d5854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "(400, 400)\n",
      "nms\n"
     ]
    }
   ],
   "source": [
    "# if not os.path.isfile(ONNX_FILE_PATH):\n",
    "ONNX_FILE_PATH = work_dir + '/'+ save_file\n",
    "torch.onnx.export(model_to_export, (x), ONNX_FILE_PATH, input_names=[\"x\"], \n",
    "                output_names=[\"bboxes\",\"scores\"], export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2926bafc-f3c5-4fd7-805a-c8cfd09a61cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa50249-b7f7-4e92-a3c9-7aeea4cc5834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ced045e-650e-4c07-a88f-b4579136e143",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: work_dirs/faster-rcnn_r50_rfla_kld_1x_aitod/epoch_12.pth\n",
      "12/25 08:28:05 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - DeprecationWarning: get_onnx_config will be deprecated in the future. \n",
      "12/25 08:28:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Export PyTorch model to ONNX: mmdeploy_models/mmdet/onnx/rfla.onnx.\n",
      "12/25 08:28:05 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Can not find torch.nn.functional._scaled_dot_product_attention, function rewrite will not be applied\n",
      "12/25 08:28:05 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Can not find mmdet.models.utils.transformer.PatchMerging.forward, function rewrite will not be applied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmdeploy/codebase/mmdet/models/detectors/two_stage.py:71: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  img_shape = [int(val) for val in img_shape]\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmdeploy/codebase/mmdet/models/detectors/two_stage.py:71: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  img_shape = [int(val) for val in img_shape]\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmdeploy/core/optimizers/function_marker.py:160: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  ys_shape = tuple(int(s) for s in ys.shape)\n",
      "/home/meysam/test-apps/mmdetection/mmdet/models/dense_heads/anchor_head.py:115: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\n",
      "/home/meysam/test-apps/mmdetection/mmdet/models/task_modules/prior_generators/rf_generator.py:288: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
      "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
      "/home/meysam/test-apps/mmdetection/mmdet/models/task_modules/prior_generators/rf_generator.py:324: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
      "  warnings.warn(\n",
      "/home/meysam/anaconda3/lib/python3.12/site-packages/mmdeploy/codebase/mmdet/models/dense_heads/rpn_head.py:89: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert cls_score.size()[-2:] == bbox_pred.size()[-2:]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to create tensor with negative dimension -1: [1, -1, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1. convert model to onnx\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# t_inp = torch.randn(1,3,800,800)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# t_inp = torch.Tensor(t_inp)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtorch2onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeploy_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/mmdeploy/apis/core/pipeline_manager.py:356\u001b[0m, in \u001b[0;36mPipelineManager.register_pipeline.<locals>._register.<locals>._wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_name_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/mmdeploy/apis/core/pipeline_manager.py:326\u001b[0m, in \u001b[0;36mPipelineManager.call_function\u001b[0;34m(self, func_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_result_sync(call_id)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/mmdeploy/apis/core/pipeline_manager.py:275\u001b[0m, in \u001b[0;36mPipelineManager.call_function_local\u001b[0;34m(self, func_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m pipe_caller\u001b[38;5;241m.\u001b[39m_call_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_id\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipe_caller\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/mmdeploy/apis/core/pipeline_manager.py:107\u001b[0m, in \u001b[0;36mPipelineCaller.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(mod, impl_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \\\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCan not find implementation of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 107\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output_hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_hooks:\n\u001b[1;32m    109\u001b[0m     ret \u001b[38;5;241m=\u001b[39m output_hook(ret)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/mmdeploy/apis/pytorch2onnx.py:98\u001b[0m, in \u001b[0;36mtorch2onnx\u001b[0;34m(img, work_dir, save_file, deploy_cfg, model_cfg, model_checkpoint, device)\u001b[0m\n\u001b[1;32m     96\u001b[0m     optimize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m no_mp():\n\u001b[0;32m---> 98\u001b[0m     \u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_metas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_metas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_path_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/mmdeploy/apis/core/pipeline_manager.py:356\u001b[0m, in \u001b[0;36mPipelineManager.register_pipeline.<locals>._register.<locals>._wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_name_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/mmdeploy/apis/core/pipeline_manager.py:326\u001b[0m, in \u001b[0;36mPipelineManager.call_function\u001b[0;34m(self, func_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_result_sync(call_id)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/mmdeploy/apis/core/pipeline_manager.py:275\u001b[0m, in \u001b[0;36mPipelineManager.call_function_local\u001b[0;34m(self, func_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m pipe_caller\u001b[38;5;241m.\u001b[39m_call_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_id\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipe_caller\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/mmdeploy/apis/core/pipeline_manager.py:107\u001b[0m, in \u001b[0;36mPipelineCaller.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(mod, impl_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \\\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCan not find implementation of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 107\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output_hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_hooks:\n\u001b[1;32m    109\u001b[0m     ret \u001b[38;5;241m=\u001b[39m output_hook(ret)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/mmdeploy/apis/onnx/export.py:138\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, output_path_prefix, backend, input_metas, context_info, input_names, output_names, opset_version, dynamic_axes, verbose, keep_initializers_as_inputs, optimize)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot supported args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 138\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatched_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_metas \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     patched_model\u001b[38;5;241m.\u001b[39mforward \u001b[38;5;241m=\u001b[39m model_forward\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/onnx/__init__.py:375\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, kwargs, export_params, verbose, input_names, output_names, opset_version, dynamic_axes, keep_initializers_as_inputs, dynamo, external_data, dynamic_shapes, report, verify, profile, dump_exported_program, artifacts_dir, fallback, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining, **_)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dynamic_shapes:\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe exporter only supports dynamic shapes \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthrough parameter dynamic_axes when dynamo=False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    373\u001b[0m     )\n\u001b[0;32m--> 375\u001b[0m \u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/onnx/utils.py:502\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, kwargs, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;241m+\u001b[39m (kwargs,)\n\u001b[0;32m--> 502\u001b[0m \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/onnx/utils.py:1564\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1562\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1564\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1578\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1579\u001b[0m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _exporter_states\u001b[38;5;241m.\u001b[39mExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1580\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/mmdeploy/apis/onnx/optimizer.py:27\u001b[0m, in \u001b[0;36mmodel_to_graph__custom_optimizer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Rewriter of _model_to_graph, add custom passes.\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m ctx \u001b[38;5;241m=\u001b[39m FUNCTION_REWRITER\u001b[38;5;241m.\u001b[39mget_context()\n\u001b[0;32m---> 27\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morigin_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ctx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopset\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     29\u001b[0m     opset_version \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mopset\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/onnx/utils.py:1113\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[1;32m   1112\u001b[0m model \u001b[38;5;241m=\u001b[39m _pre_trace_quant_model(model, args)\n\u001b[0;32m-> 1113\u001b[0m graph, params, torch_out, module \u001b[38;5;241m=\u001b[39m \u001b[43m_create_jit_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/onnx/utils.py:997\u001b[0m, in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    992\u001b[0m     graph \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_propagate_and_assign_input_shapes(\n\u001b[1;32m    993\u001b[0m         graph, flattened_args, param_count_list, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    994\u001b[0m     )\n\u001b[1;32m    995\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, params, torch_out, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 997\u001b[0m graph, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_and_get_graph_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m    999\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_unique_state_dict(model)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/onnx/utils.py:904\u001b[0m, in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    902\u001b[0m prev_autocast_cache_enabled \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_cache_enabled()\n\u001b[1;32m    903\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 904\u001b[0m trace_graph, torch_out, inputs_states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(prev_autocast_cache_enabled)\n\u001b[1;32m    913\u001b[0m warn_on_static_input_change(inputs_states)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/jit/_trace.py:1500\u001b[0m, in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m   1499\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[0;32m-> 1500\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mONNXTracedModule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/jit/_trace.py:139\u001b[0m, in \u001b[0;36mONNXTracedModule.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(out_vars)\n\u001b[0;32m--> 139\u001b[0m graph, out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_by_tracing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_vars\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_create_interpreter_name_lookup_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, outs[\u001b[38;5;241m0\u001b[39m], ret_inputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/jit/_trace.py:130\u001b[0m, in \u001b[0;36mONNXTracedModule.forward.<locals>.wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs_states:\n\u001b[1;32m    129\u001b[0m     inputs_states\u001b[38;5;241m.\u001b[39mappend(_unflatten(in_args, in_desc))\n\u001b[0;32m--> 130\u001b[0m outs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrace_inputs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs_states:\n\u001b[1;32m    132\u001b[0m     inputs_states[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m (inputs_states[\u001b[38;5;241m0\u001b[39m], trace_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1726\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1724\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1725\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1726\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1728\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/mmdeploy/apis/onnx/export.py:123\u001b[0m, in \u001b[0;36mexport.<locals>.wrap_forward.<locals>.wrapper\u001b[0;34m(*arg, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39marg, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/mmdeploy/codebase/mmdet/models/detectors/two_stage.py:83\u001b[0m, in \u001b[0;36mtwo_stage_detector__forward\u001b[0;34m(self, batch_inputs, data_samples, mode, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_feat(batch_inputs)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_samples[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproposals\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     rpn_results_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrpn_head\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrescale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m     rpn_results_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     87\u001b[0m         data_sample\u001b[38;5;241m.\u001b[39mproposals \u001b[38;5;28;01mfor\u001b[39;00m data_sample \u001b[38;5;129;01min\u001b[39;00m data_samples\n\u001b[1;32m     88\u001b[0m     ]\n",
      "File \u001b[0;32m~/test-apps/mmdetection/mmdet/models/dense_heads/base_dense_head.py:197\u001b[0m, in \u001b[0;36mBaseDenseHead.predict\u001b[0;34m(self, x, batch_data_samples, rescale)\u001b[0m\n\u001b[1;32m    191\u001b[0m batch_img_metas \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    192\u001b[0m     data_samples\u001b[38;5;241m.\u001b[39mmetainfo \u001b[38;5;28;01mfor\u001b[39;00m data_samples \u001b[38;5;129;01min\u001b[39;00m batch_data_samples\n\u001b[1;32m    193\u001b[0m ]\n\u001b[1;32m    195\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n\u001b[0;32m--> 197\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_by_feat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_img_metas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_img_metas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrescale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrescale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/mmdeploy/codebase/mmdet/models/dense_heads/rpn_head.py:113\u001b[0m, in \u001b[0;36mrpn_head__predict_by_feat\u001b[0;34m(self, cls_scores, bbox_preds, score_factors, batch_img_metas, cfg, rescale, with_nms, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m anchors \u001b[38;5;241m=\u001b[39m anchors\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# topk in tensorrt does not support shape<k\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# concate zero to enable topk,\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mpad_with_value_if_necessary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_topk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m bbox_pred \u001b[38;5;241m=\u001b[39m pad_with_value_if_necessary(bbox_pred, \u001b[38;5;241m1\u001b[39m, pre_topk)\n\u001b[1;32m    115\u001b[0m anchors \u001b[38;5;241m=\u001b[39m pad_with_value_if_necessary(anchors, \u001b[38;5;241m1\u001b[39m, pre_topk)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/mmdeploy/codebase/mmdet/deploy/utils.py:142\u001b[0m, in \u001b[0;36mpad_with_value_if_necessary\u001b[0;34m(x, pad_dim, pad_size, pad_value)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpad_with_value_if_necessary\u001b[39m(x: Tensor,\n\u001b[1;32m    128\u001b[0m                                 pad_dim: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    129\u001b[0m                                 pad_size: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    130\u001b[0m                                 pad_value: Optional[Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Pad a tensor with a value along some dim if necessary.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m        Tensor: Padded tensor.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__pad_with_value_if_necessary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/mmdeploy/codebase/mmdet/deploy/utils.py:183\u001b[0m, in \u001b[0;36m__pad_with_value_if_necessary__tensorrt\u001b[0;34m(x, pad_dim, pad_size, pad_value)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;129m@FUNCTION_REWRITER\u001b[39m\u001b[38;5;241m.\u001b[39mregister_rewriter(\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmmdeploy.codebase.mmdet.deploy.utils.__pad_with_value_if_necessary\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    166\u001b[0m     backend\u001b[38;5;241m=\u001b[39mBackend\u001b[38;5;241m.\u001b[39mTENSORRT\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         pad_size: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    171\u001b[0m         pad_value: Optional[Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Pad a tensor with a value along some dim.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m        Tensor: Padded tensor.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpad_with_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/mmdeploy/codebase/mmdet/deploy/utils.py:120\u001b[0m, in \u001b[0;36mpad_with_value\u001b[0;34m(x, pad_dim, pad_size, pad_value)\u001b[0m\n\u001b[1;32m    118\u001b[0m x_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    119\u001b[0m pad_shape \u001b[38;5;241m=\u001b[39m x_shape[:pad_dim] \u001b[38;5;241m+\u001b[39m [pad_size] \u001b[38;5;241m+\u001b[39m x_shape[pad_dim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 120\u001b[0m x_pad \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pad_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     x_pad \u001b[38;5;241m=\u001b[39m x_pad \u001b[38;5;241m+\u001b[39m pad_value\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to create tensor with negative dimension -1: [1, -1, 1]"
     ]
    }
   ],
   "source": [
    "# 1. convert model to onnx\n",
    "# t_inp = torch.randn(1,3,800,800)\n",
    "# t_inp = torch.Tensor(t_inp)\n",
    "torch2onnx(img, work_dir, save_file, deploy_cfg, model_cfg,\n",
    "           model_checkpoint, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a8127a-e84e-42d3-b62f-18ac28de6a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d528f7a0-e100-4d8d-bfef-3e3b318bb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = work_dir + '/' + save_file\n",
    "onnx_model = onnx.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e388f5-9755-4de2-918a-4fb00773b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx_model.graph.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d9d47-3844-4b96-8a37-45d7d8e95276",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_model = [work_dir + '/' + save_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915621ed-0e5f-4e58-b54f-f89a44216b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read deploy_cfg and model_cfg\n",
    "deploy_cfg, model_cfg = load_config(deploy_cfg, model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d99b3-7eb1-48ec-86bf-7a7dfba024e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build task and backend model\n",
    "task_processor = build_task_processor(model_cfg, deploy_cfg, device)\n",
    "model = task_processor.build_backend_model(backend_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830ad006-b831-402a-9a0b-55fe65d745dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c7166-80b5-4dec-aa85-9d1fc7a9629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "task_processor = build_task_processor(model_cfg, deploy_cfg, device)\n",
    "\n",
    "# process input image\n",
    "input_shape = get_input_shape(deploy_cfg)\n",
    "model_inputs, _ = task_processor.create_input(img, input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c6bf5-690a-43db-802e-718f903f8e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_cfg, model_cfg = load_config(deploy_cfg, model_cfg)\n",
    "task_processor = build_task_processor(model_cfg, deploy_cfg, device)\n",
    "torch_model = task_processor.build_pytorch_model(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f9b794-9ec8-45ce-a088-bca8bc1affe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(torch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1762ad-30bc-4e7d-b14d-c70415798056",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10705a8e-d80e-4af3-8478-6acbeee2969a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1400aaa-a5fd-4323-bf29-14d49d823d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459959a6-3478-479c-bb7d-5d5ed5b85733",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63baf173-37b1-43f9-8596-7ad9611001ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0].get('pred_instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a0283c-e835-4a5a-8fc6-69f6a2decc54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb95c717-4db7-475b-9eb6-3b34142d553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = get_input_shape(deploy_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb843f5-b1e3-430e-853d-cefd6e74e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = get_input_shape(deploy_cfg)\n",
    "model_inputs, _ = task_processor.create_input(img, input_shape)\n",
    "model_inputs.get('data_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dab49d-8553-4550-a4e3-2e6b1f22859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs.get('data_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ca475-f03e-450d-918f-d2db752dc50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    result = model.test_step(model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ff090c-e79d-42f1-873e-35c130f621bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0].get('pred_instances').scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c810bb05-aa8c-4c30-9e1d-a20b0e18a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1,3,800,800)\n",
    "feat = torch_model.extract_feat(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a8a9d-3c41-4a70-a329-419249d04546",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eedd51-2d4d-45b2-bac2-fffadcfa81c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in feat:\n",
    "    print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354e579d-ee53-4c06-b920-0565f6b7c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4463f3-1688-4b5e-91ac-c637d2a39cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31b65c7b-d60d-4078-b23d-616b641d6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = work_dir + '/' + save_file\n",
    "onnx_model = onnx.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb082abd-f912-43c8-904d-c65093c31943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "onnx.onnx_ml_pb2.ModelProto"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f4ea04b-42a4-41a7-88f5-46f139ab58a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677 input: \"/Equal_output_0\"\n",
      "output: \"/NonZero_output_0\"\n",
      "name: \"/NonZero\"\n",
      "op_type: \"NonZero\"\n",
      "\n",
      "690 input: \"/Expand_16_output_0\"\n",
      "output: \"/NonZero_1_output_0\"\n",
      "name: \"/NonZero_1\"\n",
      "op_type: \"NonZero\"\n",
      "\n",
      "724 input: \"/Equal_2_output_0\"\n",
      "output: \"/NonZero_2_output_0\"\n",
      "name: \"/NonZero_2\"\n",
      "op_type: \"NonZero\"\n",
      "\n",
      "737 input: \"/Expand_18_output_0\"\n",
      "output: \"/NonZero_3_output_0\"\n",
      "name: \"/NonZero_3\"\n",
      "op_type: \"NonZero\"\n",
      "\n",
      "778 input: \"/Equal_4_output_0\"\n",
      "output: \"/NonZero_4_output_0\"\n",
      "name: \"/NonZero_4\"\n",
      "op_type: \"NonZero\"\n",
      "\n",
      "791 input: \"/Expand_20_output_0\"\n",
      "output: \"/NonZero_5_output_0\"\n",
      "name: \"/NonZero_5\"\n",
      "op_type: \"NonZero\"\n",
      "\n",
      "832 input: \"/Equal_6_output_0\"\n",
      "output: \"/NonZero_6_output_0\"\n",
      "name: \"/NonZero_6\"\n",
      "op_type: \"NonZero\"\n",
      "\n",
      "845 input: \"/Expand_22_output_0\"\n",
      "output: \"/NonZero_7_output_0\"\n",
      "name: \"/NonZero_7\"\n",
      "op_type: \"NonZero\"\n",
      "\n",
      "886 input: \"/Equal_8_output_0\"\n",
      "output: \"/NonZero_8_output_0\"\n",
      "name: \"/NonZero_8\"\n",
      "op_type: \"NonZero\"\n",
      "\n",
      "899 input: \"/Expand_24_output_0\"\n",
      "output: \"/NonZero_9_output_0\"\n",
      "name: \"/NonZero_9\"\n",
      "op_type: \"NonZero\"\n",
      "\n",
      "938 input: \"/ScatterND_8_output_0\"\n",
      "output: \"/NonZero_10_output_0\"\n",
      "name: \"/NonZero_10\"\n",
      "op_type: \"NonZero\"\n",
      "\n",
      "996 input: \"/bbox_roi_extractor/Equal_output_0\"\n",
      "output: \"/bbox_roi_extractor/NonZero_output_0\"\n",
      "name: \"/bbox_roi_extractor/NonZero\"\n",
      "op_type: \"NonZero\"\n",
      "\n",
      "1023 input: \"/bbox_roi_extractor/Equal_1_output_0\"\n",
      "output: \"/bbox_roi_extractor/NonZero_1_output_0\"\n",
      "name: \"/bbox_roi_extractor/NonZero_1\"\n",
      "op_type: \"NonZero\"\n",
      "\n",
      "1050 input: \"/bbox_roi_extractor/Equal_2_output_0\"\n",
      "output: \"/bbox_roi_extractor/NonZero_2_output_0\"\n",
      "name: \"/bbox_roi_extractor/NonZero_2\"\n",
      "op_type: \"NonZero\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, g in enumerate(onnx_model.graph.node):\n",
    "    # print(g)\n",
    "    if \"NonZero\" in  g.op_type:\n",
    "        print(i , g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0217049c-4faa-42c4-b6de-8db6f910ba8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input: \"/Transpose_2_output_0\"\n",
       "input: \"/Constant_96_output_0\"\n",
       "output: \"/Reshape_15_output_0\"\n",
       "name: \"/Reshape_15\"\n",
       "op_type: \"Reshape\"\n",
       "attribute {\n",
       "  name: \"allowzero\"\n",
       "  i: 0\n",
       "  type: INT\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model.graph.node[460]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e604ad8-45e3-4bcc-b584-a3de84f026cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (data_preprocessor): DetDataPreprocessor()\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
       "  (neck): FPN(\n",
       "    (lateral_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (3): ConvModule(\n",
       "        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (fpn_convs): ModuleList(\n",
       "      (0-3): 4 x ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
       "  (rpn_head): RPNHead(\n",
       "    (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n",
       "    (loss_bbox): L1Loss()\n",
       "    (rpn_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (rpn_cls): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (rpn_reg): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
       "  (roi_head): StandardRoIHead(\n",
       "    (bbox_roi_extractor): SingleRoIExtractor(\n",
       "      (roi_layers): ModuleList(\n",
       "        (0): RoIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "        (1): RoIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "        (2): RoIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "        (3): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "      )\n",
       "    )\n",
       "    (bbox_head): Shared2FCBBoxHead(\n",
       "      (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n",
       "      (loss_bbox): L1Loss()\n",
       "      (fc_cls): Linear(in_features=1024, out_features=9, bias=True)\n",
       "      (fc_reg): Linear(in_features=1024, out_features=32, bias=True)\n",
       "      (shared_convs): ModuleList()\n",
       "      (shared_fcs): ModuleList(\n",
       "        (0): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "        (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (cls_convs): ModuleList()\n",
       "      (cls_fcs): ModuleList()\n",
       "      (reg_convs): ModuleList()\n",
       "      (reg_fcs): ModuleList()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2115a78-14ea-41a4-818b-528c5b1f47f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
